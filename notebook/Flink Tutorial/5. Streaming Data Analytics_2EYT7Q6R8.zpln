{
  "paragraphs": [
    {
      "title": "Overview",
      "text": "%md\n\nThis tutorial demonstrate how to use Flink do streaming analytics via its streaming sql + udf. Zeppelin now support 3 kinds of streaming visualization.\n\n* Single  - Single mode is for the case when the result of sql statement is always one row, such as the following example\n* Update  - Update mode is suitable for the case when the output is more than one rows, and always will be updated continuously. \n* Append  - Append mode is suitable for the scenario where output data is always appended\n\n",
      "user": "anonymous",
      "dateUpdated": "2020-04-29 15:31:49.376",
      "config": {
        "runOnSelectionChange": true,
        "title": true,
        "checkEmpty": true,
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eThis tutorial demonstrate how to use Flink do streaming analytics via its streaming sql + udf. Zeppelin now support 3 kinds of streaming visualization.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eSingle  - Single mode is for the case when the result of sql statement is always one row, such as the following example\u003c/li\u003e\n\u003cli\u003eUpdate  - Update mode is suitable for the case when the output is more than one rows, and always will be updated continuously.\u003c/li\u003e\n\u003cli\u003eAppend  - Append mode is suitable for the scenario where output data is always appended\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1579054784565_2122156822",
      "id": "paragraph_1579054784565_2122156822",
      "dateCreated": "2020-01-15 10:19:44.565",
      "dateStarted": "2020-04-29 15:31:49.379",
      "dateFinished": "2020-04-29 15:31:49.549",
      "status": "FINISHED"
    },
    {
      "title": "Single row mode of Output",
      "text": "%flink.ssql(type\u003dsingle, parallelism\u003d1, refreshInterval\u003d3000, template\u003d\u003ch1\u003e{1}\u003c/h1\u003e until \u003ch2\u003e{0}\u003c/h2\u003e)\n\nselect max(event_ts), count(1) from sink_kafka\n",
      "user": "anonymous",
      "dateUpdated": "2020-04-29 15:45:47.116",
      "config": {
        "runOnSelectionChange": true,
        "title": true,
        "checkEmpty": true,
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/sql",
        "template": "\u003ch1\u003e{1}\u003c/h1\u003e until \u003ch2\u003e{0}\u003c/h2\u003e",
        "refreshInterval": "3000",
        "parallelism": "1",
        "type": "single"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1578909960516_-1812187661",
      "id": "paragraph_1578909960516_-1812187661",
      "dateCreated": "2020-01-13 18:06:00.516",
      "dateStarted": "2020-04-29 15:45:47.127",
      "dateFinished": "2020-04-29 15:47:14.738",
      "status": "ABORT"
    },
    {
      "title": "Update mode of Output",
      "text": "%flink.ssql(type\u003dupdate, refreshInterval\u003d2000, parallelism\u003d1)\n\nselect status, count(1) as pv from sink_kafka group by status",
      "user": "anonymous",
      "dateUpdated": "2020-04-29 15:46:09.485",
      "config": {
        "runOnSelectionChange": true,
        "title": true,
        "checkEmpty": true,
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {
          "0": {
            "graph": {
              "mode": "multiBarChart",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "multiBarChart": {
                  "xLabelStatus": "default",
                  "rotate": {
                    "degree": "-45"
                  }
                }
              },
              "commonSetting": {},
              "keys": [
                {
                  "name": "status",
                  "index": 0.0,
                  "aggr": "sum"
                }
              ],
              "groups": [],
              "values": [
                {
                  "name": "pv",
                  "index": 1.0,
                  "aggr": "sum"
                }
              ]
            },
            "helium": {}
          }
        },
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/sql",
        "refreshInterval": "2000",
        "parallelism": "1",
        "type": "update",
        "savepointDir": "/tmp/flink_2",
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1578910004762_-286113604",
      "id": "paragraph_1578910004762_-286113604",
      "dateCreated": "2020-01-13 18:06:44.762",
      "dateStarted": "2020-04-29 15:46:09.492",
      "dateFinished": "2020-04-29 15:47:13.312",
      "status": "ABORT"
    },
    {
      "title": "Append mode of Output",
      "text": "%flink.ssql(type\u003dappend, parallelism\u003d1, refreshInterval\u003d2000, threshold\u003d60000)\n\nselect TUMBLE_START(event_ts, INTERVAL \u00275\u0027 SECOND) as start_time, status, count(1) from sink_kafka\ngroup by TUMBLE(event_ts, INTERVAL \u00275\u0027 SECOND), status\n",
      "user": "anonymous",
      "dateUpdated": "2020-04-29 15:46:40.174",
      "config": {
        "runOnSelectionChange": true,
        "title": true,
        "checkEmpty": true,
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {
          "0": {
            "graph": {
              "mode": "lineChart",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "lineChart": {
                  "xLabelStatus": "rotate",
                  "rotate": {
                    "degree": "-45"
                  }
                }
              },
              "commonSetting": {},
              "keys": [
                {
                  "name": "start_time",
                  "index": 0.0,
                  "aggr": "sum"
                }
              ],
              "groups": [
                {
                  "name": "status",
                  "index": 1.0,
                  "aggr": "sum"
                }
              ],
              "values": [
                {
                  "name": "EXPR$2",
                  "index": 2.0,
                  "aggr": "sum"
                }
              ]
            },
            "helium": {}
          }
        },
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/sql",
        "refreshInterval": "2000",
        "parallelism": "1",
        "threshold": "60000",
        "type": "append",
        "savepointDir": "/tmp/flink_3"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "ERROR",
        "msg": [
          {
            "type": "TABLE",
            "data": "start_time\tstatus\tEXPR$2\n2020-04-29 07:46:20.0\tbaz\t3\n2020-04-29 07:46:20.0\tbar\t3\n2020-04-29 07:46:25.0\tbaz\t2\n2020-04-29 07:46:25.0\tbar\t4\n2020-04-29 07:46:30.0\tbar\t4\n2020-04-29 07:46:30.0\tbaz\t2\n2020-04-29 07:46:35.0\tbar\t4\n2020-04-29 07:46:40.0\tbar\t5\n2020-04-29 07:46:40.0\tbaz\t2\n2020-04-29 07:46:45.0\tbar\t4\n2020-04-29 07:46:45.0\tbaz\t4\n2020-04-29 07:46:50.0\tbar\t4\n2020-04-29 07:46:50.0\tbaz\t3\n2020-04-29 07:46:55.0\tbaz\t3\n2020-04-29 07:46:55.0\tbar\t2\n2020-04-29 07:47:00.0\tbaz\t1\n2020-04-29 07:47:00.0\tbar\t6\n2020-04-29 07:47:05.0\tbaz\t2\n2020-04-29 07:47:05.0\tbar\t4\n"
          },
          {
            "type": "TEXT",
            "data": "Fail to run sql command: select TUMBLE_START(event_ts, INTERVAL \u00275\u0027 SECOND) as start_time, status, count(1) from sink_kafka\ngroup by TUMBLE(event_ts, INTERVAL \u00275\u0027 SECOND), status\njava.io.IOException: Fail to run stream sql job\n\tat org.apache.zeppelin.flink.sql.AbstractStreamSqlJob.run(AbstractStreamSqlJob.java:166)\n\tat org.apache.zeppelin.flink.sql.AbstractStreamSqlJob.run(AbstractStreamSqlJob.java:101)\n\tat org.apache.zeppelin.flink.FlinkStreamSqlInterpreter.callInnerSelect(FlinkStreamSqlInterpreter.java:82)\n\tat org.apache.zeppelin.flink.FlinkSqlInterrpeter.callSelect(FlinkSqlInterrpeter.java:487)\n\tat org.apache.zeppelin.flink.FlinkSqlInterrpeter.callCommand(FlinkSqlInterrpeter.java:283)\n\tat org.apache.zeppelin.flink.FlinkSqlInterrpeter.runSqlList(FlinkSqlInterrpeter.java:197)\n\tat org.apache.zeppelin.flink.FlinkSqlInterrpeter.interpret(FlinkSqlInterrpeter.java:171)\n\tat org.apache.zeppelin.interpreter.LazyOpenInterpreter.interpret(LazyOpenInterpreter.java:110)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:684)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:577)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:172)\n\tat org.apache.zeppelin.scheduler.AbstractScheduler.runJob(AbstractScheduler.java:130)\n\tat org.apache.zeppelin.scheduler.ParallelScheduler.lambda$runJobInScheduler$0(ParallelScheduler.java:39)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.util.concurrent.ExecutionException: org.apache.flink.client.program.ProgramInvocationException: Job failed (JobID: 12995bca62e4fad2c41bb6756fc91e40)\n\tat java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:357)\n\tat java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1895)\n\tat org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1640)\n\tat org.apache.flink.api.java.ScalaShellStreamEnvironment.execute(ScalaShellStreamEnvironment.java:80)\n\tat org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1620)\n\tat org.apache.flink.table.planner.delegation.StreamExecutor.execute(StreamExecutor.java:42)\n\tat org.apache.flink.table.api.internal.TableEnvironmentImpl.execute(TableEnvironmentImpl.java:643)\n\tat org.apache.zeppelin.flink.sql.AbstractStreamSqlJob.run(AbstractStreamSqlJob.java:155)\n\t... 15 more\nCaused by: org.apache.flink.client.program.ProgramInvocationException: Job failed (JobID: 12995bca62e4fad2c41bb6756fc91e40)\n\tat org.apache.flink.client.deployment.ClusterClientJobClientAdapter.lambda$null$6(ClusterClientJobClientAdapter.java:112)\n\tat java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:602)\n\tat java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:577)\n\tat java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:474)\n\tat java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:1962)\n\tat org.apache.flink.client.program.rest.RestClusterClient.lambda$pollResourceAsync$21(RestClusterClient.java:565)\n\tat java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:760)\n\tat java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:736)\n\tat java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:474)\n\tat java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:1962)\n\tat org.apache.flink.runtime.concurrent.FutureUtils.lambda$retryOperationWithDelay$8(FutureUtils.java:291)\n\tat java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:760)\n\tat java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:736)\n\tat java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:474)\n\tat java.util.concurrent.CompletableFuture.postFire(CompletableFuture.java:561)\n\tat java.util.concurrent.CompletableFuture$UniCompose.tryFire(CompletableFuture.java:929)\n\tat java.util.concurrent.CompletableFuture$Completion.run(CompletableFuture.java:442)\n\t... 3 more\nCaused by: org.apache.flink.runtime.client.JobCancellationException: Job was cancelled.\n\tat org.apache.flink.runtime.jobmaster.JobResult.toJobExecutionResult(JobResult.java:149)\n\tat org.apache.flink.client.deployment.ClusterClientJobClientAdapter.lambda$null$6(ClusterClientJobClientAdapter.java:110)\n\t... 19 more\n\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1578910016872_1942851900",
      "id": "paragraph_1578910016872_1942851900",
      "dateCreated": "2020-01-13 18:06:56.872",
      "dateStarted": "2020-04-29 15:46:18.958",
      "dateFinished": "2020-04-29 15:47:22.960",
      "status": "ABORT"
    },
    {
      "text": "%flink.ssql\n",
      "user": "anonymous",
      "dateUpdated": "2020-01-13 21:17:35.739",
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1578921455738_-1465781668",
      "id": "paragraph_1578921455738_-1465781668",
      "dateCreated": "2020-01-13 21:17:35.739",
      "status": "READY"
    }
  ],
  "name": "5. Streaming Data Analytics",
  "id": "2EYT7Q6R8",
  "defaultInterpreterGroup": "flink",
  "version": "0.9.0-SNAPSHOT",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {},
  "config": {
    "isZeppelinNotebookCronEnable": false
  },
  "info": {}
}